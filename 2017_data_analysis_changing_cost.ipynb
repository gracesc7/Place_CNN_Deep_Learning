{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Changing Cost \n",
    "gb='good'\n",
    "layer_list=['fc8']\n",
    "#layer_list=['conv1','conv2','conv3','conv4','conv5','fc6','fc7','fc8']\n",
    "cost = np.linspace(10**-2,10**2,100)\n",
    "cost=cost.tolist()\n",
    "param_grid = {'C': cost}\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "y_good=[1]*27+[2]*31+[3]*39+[4]*46+[5]*25+[6]*42\n",
    "#y_good=np.asarray(y_good)\n",
    "y_bad=[1]*34+[2]*39+[3]*32+[4]*31+[5]*42+[6]*32\n",
    "#y_bad=np.asarray(y_bad)\n",
    "if gb=='good':\n",
    "    y=y_good\n",
    "    for layer in layer_list:\n",
    "        list0= open('/Users/sczha/Documents/RESEARCH/features/'+gb+\"/\"+gb+\"_\"+layer+\".txt\", \"r\")\n",
    "        X_good=[]\n",
    "        for line in list0:\n",
    "            X_good.append(line.split())\n",
    "        X_good=[[float(j) for j in i] for i in X_good]\n",
    "        X_good=np.asarray(X_good)\n",
    "        X=X_good \n",
    "        n_sample= 210\n",
    "        n_features=np.size(X)/210\n",
    "        n_components = min(n_sample,n_features)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_good, test_size=0.1, random_state=0)\n",
    "        pca = PCA( n_components=n_components,svd_solver='randomized', whiten=True).fit(X_train)\n",
    "        #X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "        clf = GridSearchCV(SVC(kernel='poly',class_weight='balanced'), param_grid,cv=cv)\n",
    "        clf=clf.fit(X_train_pca, y_train)\n",
    "        #score_good=cross_val_score(clf, X, y, cv=cv)\n",
    "        print(layer)\n",
    "            #print clf.best_estimator_\n",
    "            #print score_good\n",
    "            #print score_good.mean()\n",
    "        print(clf.best_estimator_)\n",
    "        #print(clf.cv_results_)\n",
    "else:\n",
    "    y=y_bad\n",
    "    for layer in layer_list:\n",
    "        list0= open('/Users/sczha/Documents/RESEARCH/features/'+gb+\"/\"+gb+\"_\"+layer+\".txt\", \"r\")\n",
    "        X_bad=[]\n",
    "        for line in list0:\n",
    "            X_bad.append(line.split())\n",
    "            X_bad=[[float(j) for j in i] for i in X_bad]\n",
    "            X_bad=np.asarray(X_bad)\n",
    "            X=X_bad\n",
    "            #score_bad=cross_val_score(clf, X, y, cv=cv)\n",
    "            n_sample= 210\n",
    "            n_features=np.size(X)/210\n",
    "            n_components = min(n_sample,n_features)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y_bad, test_size=0.1, random_state=0)\n",
    "            pca = PCA( n_components=n_components,svd_solver='randomized', whiten=True).fit(X_train)\n",
    "            #X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "            X_train_pca = pca.transform(X_train)\n",
    "            X_test_pca = pca.transform(X_test)\n",
    "            clf = GridSearchCV(SVC(kernel='poly',class_weight='balanced'), param_grid,cv=cv)\n",
    "            clf=clf.fit(X_train_pca, y_train)\n",
    "            #score_good=cross_val_score(clf, X, y, cv=cv)\n",
    "            print(layer)\n",
    "            print(clf.best_estimator_)\n",
    "            #print(clf.cv_results_)\n",
    " \n",
    " #-------------fc7-------------------\n",
    "# SVC(C=2.03, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "#   decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
    "#   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#   tol=0.001, verbose=False)\n",
    " #------------fc8-------------------\n",
    "# SVC(C=2.03, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "#   decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
    "#   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#   tol=0.001, verbose=False)\n",
    "\n",
    "#BEST COST: 2.03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
