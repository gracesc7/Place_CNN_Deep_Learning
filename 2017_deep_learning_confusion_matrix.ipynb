{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.0, 14.0, 13.666666666666666, 13.75, 13.4, 13.833333333333334, 13.714285714285714, 13.75, 14.0, 13.9]\n",
      "[18.0, 17.5, 18.333333333333332, 18.0, 18.399999999999999, 18.166666666666668, 18.428571428571427, 18.5, 18.555555555555557, 18.699999999999999]\n",
      "[19.0, 19.0, 19.0, 19.25, 19.399999999999999, 19.166666666666668, 19.428571428571427, 19.5, 19.555555555555557, 19.600000000000001]\n",
      "[20.0, 19.5, 19.0, 19.25, 19.399999999999999, 19.166666666666668, 19.428571428571427, 19.5, 19.444444444444443, 19.5]\n",
      "[20.0, 20.0, 20.333333333333332, 20.25, 20.0, 19.833333333333332, 20.0, 20.125, 20.222222222222221, 20.199999999999999]\n",
      "[21.0, 20.5, 20.666666666666668, 20.75, 20.800000000000001, 20.666666666666668, 20.714285714285715, 20.75, 20.777777777777779, 20.800000000000001]\n",
      "[20.0, 20.5, 20.666666666666668, 20.75, 20.800000000000001, 20.333333333333332, 20.428571428571427, 20.5, 20.555555555555557, 20.600000000000001]\n",
      "[21.0, 21.0, 21.0, 21.0, 20.800000000000001, 20.333333333333332, 20.285714285714285, 20.375, 20.444444444444443, 20.399999999999999]\n"
     ]
    }
   ],
   "source": [
    "#six way classification \n",
    "#original one \n",
    "gb='good'\n",
    "#layer_list=['conv1','conv2','conv3']\n",
    "layer_list=['conv1','conv2','conv3','conv4','conv5','fc6','fc7','fc8']\n",
    "#layer_list=['conv1','conv2','conv3','conv4','conv5','fc6','fc7']\n",
    "clf = svm.SVC(kernel='linear', C=2.03)   \n",
    "#cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "y_good=[1]*27+[2]*31+[3]*39+[4]*46+[5]*25+[6]*42 \n",
    "#y-true\n",
    "y_good=np.asarray(y_good)\n",
    "y_bad=[1]*34+[2]*39+[3]*32+[4]*31+[5]*42+[6]*32\n",
    "#y-true\n",
    "y_bad=np.asarray(y_bad)\n",
    "if gb=='good':\n",
    "    score_dict_g={}\n",
    "    y=y_good\n",
    "    for layer in layer_list:\n",
    "        #print(layer)\n",
    "        list0= open(\"/Users/manoj/good_bad_placecnn/features/good/good_\"+layer+\".txt\", \"r\") \n",
    "        X_good=[]\n",
    "        for line in list0:\n",
    "            X_good.append(line.split())\n",
    "        X_good=[[float(j) for j in i] for i in X_good]\n",
    "        X_good=np.asarray(X_good)\n",
    "        X=X_good\n",
    "        #kf = KFold(n_splits=10)\n",
    "        ss=ShuffleSplit(n_splits=10,random_state=0)\n",
    "        accuracy=[]\n",
    "        avg_score_list=[]\n",
    "        #kf = KFold(len(y), n_splits=10)\n",
    "        for train_index, test_index in ss.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            #model.fit(X_train, y_train)\n",
    "            y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "            #print y_test\n",
    "            #print y_pred\n",
    "            #print(len(y_test))\n",
    "            cm=confusion_matrix(y_pred, y_test,labels=range(1,7))\n",
    "            sum1=np.sum(np.diagonal(cm))\n",
    "            accuracy.extend([sum1])\n",
    "            avg_score=np.mean(accuracy)\n",
    "            avg_score_list.extend([avg_score])\n",
    "            #print cm \n",
    "        print avg_score_list\n",
    "#         print(len(X_train))\n",
    "#         print(X_test)\n",
    "#         print(y_train)\n",
    "        #print(len(y_test))\n",
    "      \n",
    "        #score_good=cross_val_score(clf, X, y, cv=cv)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, random_state=0 )\n",
    "        #svm = SVC(kernel='linear')\n",
    "        #y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "        #print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "\n",
    "else: \n",
    "    score_dict_b={}\n",
    "    y=y_bad\n",
    "    for layer in layer_list:\n",
    "        print(layer)\n",
    "        list0= open('/Users/sczha/Documents/RESEARCH/features/'+gb+\"/\"+gb+\"_\"+layer+\".txt\", \"r\")\n",
    "        X_bad=[]\n",
    "        for line in list0:\n",
    "            X_bad.append(line.split())\n",
    "        X_bad=[[float(j) for j in i] for i in X_bad]\n",
    "        X_bad=np.asarray(X_bad)\n",
    "        X=X_bad\n",
    "        ss=ShuffleSplit(n_splits=10,random_state=0)\n",
    "        accuracy=[]\n",
    "        #kf = KFold(len(y), n_splits=10)\n",
    "        for train_index, test_index in ss.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            #model.fit(X_train, y_train)\n",
    "            y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "            #print y_test\n",
    "            #print y_pred\n",
    "            #print(len(y_test))\n",
    "            cm=confusion_matrix(y_pred, y_test,labels=range(1,7))\n",
    "            sum1=np.sum(np.diagonal(cm))\n",
    "            accuracy.extend([sum1])\n",
    "            avg_score=np.mean(accuracy)\n",
    "            #print cm \n",
    "        print avg_score\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, random_state=0)\n",
    "        \n",
    "        y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "        cm=confusion_matrix(y_pred, y_test)\n",
    "        print cm.mean()\n",
    "        #score_bad=cross_val_score(clf, X, y, cv=cv)\n",
    "        #svm = SVC(kernel='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4\n"
     ]
    }
   ],
   "source": [
    "print avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583333333333\n"
     ]
    }
   ],
   "source": [
    "print cm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 3 0 0]\n",
      " [0 0 0 0 5 0]\n",
      " [0 0 0 0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "print cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 0 6 0 0 0]\n",
      " [0 0 0 2 0 0]\n",
      " [0 0 0 0 2 0]\n",
      " [0 0 0 0 0 4]]\n",
      "[[1 0 0 0 0 0]\n",
      " [0 4 0 0 0 0]\n",
      " [0 0 5 0 0 0]\n",
      " [0 1 0 6 0 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 0 3]]\n",
      "[[4 0 0 0 0 0]\n",
      " [0 3 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 2 0 0]\n",
      " [0 0 0 0 5 0]\n",
      " [0 0 0 0 0 6]]\n",
      "[[2 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 3 0 0 0]\n",
      " [0 0 0 6 0 0]\n",
      " [0 0 0 0 5 0]\n",
      " [0 0 0 0 0 3]]\n",
      "[21.0, 20.5, 20.666666666666668, 20.75]\n",
      "[0.58333333333333337, 0.58333333333333337, 0.58333333333333337, 0.58333333333333337]\n",
      "[21, 20, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "#six way classification \n",
    "#original one \n",
    "gb='good'\n",
    "#layer_list=['conv1','conv2','conv3']\n",
    "layer_list=['fc6']\n",
    "#layer_list=['conv1','conv2','conv3','conv4','conv5','fc6','fc7']\n",
    "clf = svm.SVC(kernel='linear', C=2.03)   \n",
    "#cv = ShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
    "y_good=[1]*27+[2]*31+[3]*39+[4]*46+[5]*25+[6]*42 \n",
    "#y-true\n",
    "y_good=np.asarray(y_good)\n",
    "y_bad=[1]*34+[2]*39+[3]*32+[4]*31+[5]*42+[6]*32\n",
    "#y-true\n",
    "y_bad=np.asarray(y_bad)\n",
    "if gb=='good':\n",
    "    score_dict_g={}\n",
    "    y=y_good\n",
    "    for layer in layer_list:\n",
    "        #print(layer)\n",
    "        list0= open(\"/Users/manoj/good_bad_placecnn/features/good/good_\"+layer+\".txt\", \"r\") \n",
    "        X_good=[]\n",
    "        for line in list0:\n",
    "            X_good.append(line.split())\n",
    "        X_good=[[float(j) for j in i] for i in X_good]\n",
    "        X_good=np.asarray(X_good)\n",
    "        X=X_good\n",
    "        #kf = KFold(n_splits=10)\n",
    "        ss=ShuffleSplit(n_splits=4,random_state=0)\n",
    "        accuracy=[]\n",
    "        avg_score_list=[]\n",
    "        cm_mean_list=[]\n",
    "        #kf = KFold(len(y), n_splits=10)\n",
    "        for train_index, test_index in ss.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            #model.fit(X_train, y_train)\n",
    "            y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "            #print y_test\n",
    "            #print y_pred\n",
    "            #print(len(y_test))\n",
    "            cm=confusion_matrix(y_pred, y_test,labels=range(1,7))\n",
    "            cm_mean=cm.mean()\n",
    "            cm_mean_list.extend([cm_mean])\n",
    "            sum1=np.sum(np.diagonal(cm))\n",
    "            accuracy.extend([sum1])\n",
    "            avg_score=np.mean(accuracy)\n",
    "            avg_score_list.extend([avg_score])\n",
    "            print cm \n",
    "        print avg_score_list\n",
    "        print cm_mean_list\n",
    "        print accuracy\n",
    "#         print(len(X_train))\n",
    "#         print(X_test)\n",
    "#         print(y_train)\n",
    "        #print(len(y_test))\n",
    "      \n",
    "        #score_good=cross_val_score(clf, X, y, cv=cv)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, random_state=0 )\n",
    "        #svm = SVC(kernel='linear')\n",
    "        #y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "        #print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "\n",
    "else: \n",
    "    score_dict_b={}\n",
    "    y=y_bad\n",
    "    for layer in layer_list:\n",
    "        print(layer)\n",
    "        list0= open('/Users/sczha/Documents/RESEARCH/features/'+gb+\"/\"+gb+\"_\"+layer+\".txt\", \"r\")\n",
    "        X_bad=[]\n",
    "        for line in list0:\n",
    "            X_bad.append(line.split())\n",
    "        X_bad=[[float(j) for j in i] for i in X_bad]\n",
    "        X_bad=np.asarray(X_bad)\n",
    "        X=X_bad\n",
    "        ss=ShuffleSplit(n_splits=4,random_state=0)\n",
    "        accuracy=[]\n",
    "        #kf = KFold(len(y), n_splits=10)\n",
    "        for train_index, test_index in ss.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            #model.fit(X_train, y_train)\n",
    "            y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "            #print y_test\n",
    "            #print y_pred\n",
    "            #print(len(y_test))\n",
    "            cm=confusion_matrix(y_pred, y_test,labels=range(1,7))\n",
    "            sum1=np.sum(np.diagonal(cm))\n",
    "            accuracy.extend([sum1])\n",
    "            avg_score=np.mean(accuracy)\n",
    "            print cm \n",
    "        #print avg_score\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.1, random_state=0)\n",
    "        \n",
    "#         y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "#         cm=confusion_matrix(y_pred, y_test)\n",
    "#         print cm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[21, 20, 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 0 0 0]\n",
      " [0 2 0 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 1 0 3 0 0]\n",
      " [0 0 0 0 5 0]\n",
      " [0 0 0 0 0 6]]\n"
     ]
    }
   ],
   "source": [
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583333333333\n"
     ]
    }
   ],
   "source": [
    "print cm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
